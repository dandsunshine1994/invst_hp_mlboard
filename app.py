# streamlit_app/app.py
from __future__ import annotations
from pathlib import Path
import io, os, json, importlib, sys
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# ==== åŸºæœ¬è®¾ç½® ====
st.set_page_config(page_title="Investor Happiness Â· Model Board", layout="wide")
def _ver(m):
    try: return importlib.import_module(m).__version__
    except Exception: return "N/A"
st.caption(f"Py {sys.version.split()[0]} | streamlit {_ver('streamlit')} | "
           f"pandas {_ver('pandas')} | numpy {_ver('numpy')} | altair {_ver('altair')}")

ART = Path(__file__).parent / "artifacts"
PROB_DIR = ART / "probas"
MODEL_DIR = ART / "models"
MET_DIR = ART / "metrics"

# ==== è¯»æ–‡ä»¶çš„è–„å°è£… ====
@st.cache_data(show_spinner=False)
def load_csv(path: Path) -> pd.DataFrame:
    return pd.read_csv(path)

@st.cache_data(show_spinner=False)
def load_json(path: Path) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

@st.cache_resource(show_spinner=False)
def lazy_load_npz(path: Path) -> dict:
    with np.load(path, allow_pickle=False) as d:
        payload = {k: d[k] for k in d.files}
    return payload

def file_exists(p: Path) -> bool:
    try:
        return p.exists()
    except Exception:
        return False

# ==== å°è¯•åŠ è½½æ ¸å¿ƒäº§ç‰© ====
missing = []
base_path = ART / "base.csv"
cov_path  = ART / "cov.csv"
aurc_path = ART / "aurc.csv"
ext_path  = ART / "ext_reports.json"
ext3_meta = MET_DIR / "ext3_meta.json"
fi_path   = MET_DIR / "feature_importance_lgb.csv"

for p in [base_path, cov_path, aurc_path, ext_path]:
    if not file_exists(p): missing.append(str(p))

if missing:
    st.error("ç¼ºå°‘ä»¥ä¸‹å¿…è¦äº§ç‰©ï¼Œè¯·ç¡®è®¤ä»“åº“ `streamlit_app/artifacts/` ä¸­å­˜åœ¨ï¼š\n" + "\n".join(missing))
    st.stop()

base_df = load_csv(base_path)
cov_df  = load_csv(cov_path)
aurc_df = load_csv(aurc_path)
ext_reports = load_json(ext_path)
ext3_info = load_json(ext3_meta) if file_exists(ext3_meta) else None
fi_df = load_csv(fi_path) if file_exists(fi_path) else None

# å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆæ¥è‡ª probas/*.npzï¼‰
model_npzs = sorted([p.stem for p in PROB_DIR.glob("*.npz")]) if PROB_DIR.exists() else []

# ==== ä¾§æ  ====
with st.sidebar:
    st.header("é€‰é¡¹")
    metric_cols = [c for c in base_df.columns if c not in ("model",)]
    default_metric = "base_macro_f1%" if "base_macro_f1%" in metric_cols else metric_cols[0]
    topk = st.slider("Top-Kï¼ˆæ’è¡Œæ¦œï¼‰", 3, min(10, len(base_df)), min(5, len(base_df)))
    sort_col = st.selectbox("æ’åºæŒ‡æ ‡", metric_cols, index=metric_cols.index(default_metric))
    sort_asc = st.checkbox("å‡åº", value=False)
    st.divider()
    model_pick = st.selectbox("é€‰æ‹©æ¨¡å‹ï¼ˆæ¦‚ç‡è¯Šæ–­/è¯¦æƒ…ï¼‰", sorted(base_df["model"].unique()))
    st.caption("è‹¥è¦æ¦‚ç‡è¯Šæ–­ï¼Œè¯·ç¡®ä¿ artifacts/probas/{æ¨¡å‹å}.npz å·²å­˜åœ¨ã€‚")
    st.divider()
    st.caption("ä¸‹è½½åŸå§‹äº§ç‰©")
    c1,c2,c3 = st.columns(3)
    with c1:
        st.download_button("â¬‡ base.csv", data=base_path.read_bytes(), file_name="base.csv")
    with c2:
        st.download_button("â¬‡ cov.csv",  data=cov_path.read_bytes(),  file_name="cov.csv")
    with c3:
        st.download_button("â¬‡ aurc.csv", data=aurc_path.read_bytes(), file_name="aurc.csv")
    st.download_button("â¬‡ ext_reports.json", data=ext_path.read_bytes(), file_name="ext_reports.json")

st.title("Investor Happiness Â· ç¦»çº¿è¯„æµ‹çœ‹æ¿")

# ==== Tab ç»“æ„ ====
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ† æ’è¡Œæ¦œ", "ğŸ¯ è¦†ç›–ç‡æ›²çº¿", "ğŸ AURC", "ğŸ” æ¨¡å‹è¯¦æƒ…", "ğŸ“ˆ æ¦‚ç‡è¯Šæ–­", "ğŸ§­ ç‰¹å¾é‡è¦æ€§"
])

# === Tab1: æ’è¡Œæ¦œ ===
with tab1:
    st.subheader("ğŸ† æ¨¡å‹æ’è¡Œæ¦œ")
    board = base_df.copy()
    board = board.sort_values(sort_col, ascending=sort_asc).reset_index(drop=True)
    st.dataframe(board.style.format(precision=2), use_container_width=True)
    st.caption("æ³¨ï¼šç™¾åˆ†åˆ¶åˆ—å¦‚ base_acc%ã€base_macro_f1%ã€prauc_c0% ç­‰å·²ä¸º 0-100 å°ºåº¦ã€‚")

    st.markdown("**Top-Kï¼ˆç”¨äºä¸‹æ¸¸å¯¼å‡º/å¯¹æ¯”ï¼‰**")
    topk_df = board.head(topk)
    st.dataframe(topk_df, use_container_width=True)

# === Tab2: è¦†ç›–ç‡æ›²çº¿ ===
with tab2:
    import altair as alt
    st.subheader("ğŸ¯ è¦†ç›–ç‡ vs æŒ‡æ ‡ï¼ˆpolicy: top1 / marginï¼‰")
    pols = st.multiselect("é€‰æ‹© policy", sorted(cov_df["policy"].unique()), default=list(cov_df["policy"].unique()))
    metric_choice = st.selectbox("æŒ‡æ ‡", ["acc%", "macro_f1%", "qwk"], index=1)
    cov_plot_df = cov_df[cov_df["policy"].isin(pols)]
    cov_plot_df["coverage"] = cov_plot_df["coverage"].astype(float)
    cov_plot_df = cov_plot_df[cov_plot_df["model"].isin(topk_df["model"])]
    base = alt.Chart(cov_plot_df).encode(
        x=alt.X("coverage:Q", title="Coverage (%)"),
        y=alt.Y(f"{metric_choice}:Q"),
        color="model:N",
        strokeDash="policy:N",
        tooltip=list(cov_plot_df.columns)
    )
    st.altair_chart(base.mark_line().interactive().properties(height=420), use_container_width=True)

# === Tab3: AURC ===
with tab3:
    import altair as alt
    st.subheader("ğŸ RC æ›²çº¿é¢ç§¯ï¼ˆAURCï¼Œè¶Šå°è¶Šå¥½ï¼‰")
    aurc_plot = aurc_df.copy()
    aurc_plot["AURC"] = aurc_plot["AURC"].astype(float)
    pick_policy = st.multiselect("é€‰æ‹© policy", sorted(aurc_plot["policy"].unique()),
                                 default=list(aurc_plot["policy"].unique()))
    sub = aurc_plot[aurc_plot["policy"].isin(pick_policy)]
    chart = alt.Chart(sub).mark_bar().encode(
        x=alt.X("AURC:Q", sort="ascending"),
        y=alt.Y("model:N", sort="-x"),
        color="policy:N",
        tooltip=list(sub.columns)
    ).properties(height=420)
    st.altair_chart(chart, use_container_width=True)

# === Tab4: æ¨¡å‹è¯¦æƒ…ï¼ˆæç«¯ç±»æŠ¥å‘Š + ext3 metaï¼‰ ===
with tab4:
    st.subheader(f"ğŸ” æ¨¡å‹è¯¦æƒ…ï¼š{model_pick}")
    # æç«¯ç±»æŠ¥å‘Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if model_pick in ext_reports:
        st.markdown("**æç«¯ç±»æŠ¥å‘Šï¼ˆç™¾åˆ†åˆ¶ï¼‰**")
        st.json(ext_reports[model_pick])
    else:
        st.info("æ²¡æœ‰æ‰¾åˆ°è¯¥æ¨¡å‹çš„æç«¯ç±»æŠ¥å‘Šï¼ˆext_reports.jsonï¼‰ã€‚")

    # ext3 é˜ˆå€¼å…ƒä¿¡æ¯
    if ext3_info is not None and model_pick == "ext3":
        st.markdown("**ext3 é˜ˆå€¼/çº¦æŸ**")
        st.json(ext3_info)
    elif model_pick == "ext3":
        st.info("æœªæ‰¾åˆ° ext3_meta.jsonã€‚")

    # åŒæ¨¡å‹å¯¹æ¯”ï¼ˆä¸å¦ä¸€ä¸ªæ¨¡å‹å·®å€¼ï¼‰
    st.markdown("**æ¨¡å‹å¯¹æ¯”ï¼ˆå·®å€¼ï¼šå½“å‰ - å¤‡é€‰ï¼‰**")
    other = st.selectbox("é€‰æ‹©å¤‡é€‰æ¨¡å‹", [m for m in base_df["model"].unique() if m != model_pick])
    cur = base_df[base_df["model"] == model_pick].set_index("model")
    oth = base_df[base_df["model"] == other].set_index("model")
    common_cols = sorted(set(cur.columns) & set(oth.columns))
    delta = (cur[common_cols].iloc[0] - oth[common_cols].iloc[0]).to_frame(name="Î”(Current - Other)")
    st.dataframe(delta.style.format(precision=2), use_container_width=True)

# === Tab5: æ¦‚ç‡è¯Šæ–­ï¼ˆéœ€è¦ probas/{model}.npzï¼‰ ===
with tab5:
    st.subheader(f"ğŸ“ˆ æ¦‚ç‡è¯Šæ–­ï¼š{model_pick}")
    npz_path = PROB_DIR / f"{model_pick}.npz"
    if not file_exists(npz_path):
        st.info(f"æœªæ‰¾åˆ° {npz_path.name}ï¼Œè¯·ç¡®è®¤å¯¼å‡ºã€‚")
    else:
        data = lazy_load_npz(npz_path)
        proba = data.get("proba", None)
        if proba is None:
            st.info("è¯¥æ¨¡å‹æ²¡æœ‰å­˜æ¦‚ç‡ï¼ˆprobaï¼‰ï¼Œä»…ä¿å­˜äº† y_predã€‚")
        else:
            pmax = proba.max(axis=1)
            psort = np.sort(proba, axis=1)
            margin = psort[:, -1] - psort[:, -2]

            c1, c2 = st.columns(2)
            with c1:
                st.markdown("**Top-1 ç½®ä¿¡åº¦åˆ†å¸ƒ**")
                fig, ax = plt.subplots()
                ax.hist(pmax, bins=25)
                ax.set_xlabel("max probability")
                ax.set_ylabel("count")
                st.pyplot(fig, clear_figure=True)
            with c2:
                st.markdown("**Top1-Top2 é—´è·ï¼ˆmarginï¼‰åˆ†å¸ƒ**")
                fig, ax = plt.subplots()
                ax.hist(margin, bins=25)
                ax.set_xlabel("p1 - p2")
                ax.set_ylabel("count")
                st.pyplot(fig, clear_figure=True)

            st.caption("æç¤ºï¼šè‹¥ä½ ä¹Ÿä¿å­˜äº† y_trueï¼Œå¯æ‰©å±•æ­¤é¡µåšæ ¡å‡†æ›²çº¿ã€PR/ROC ç­‰ã€‚")

# === Tab6: ç‰¹å¾é‡è¦æ€§ï¼ˆLGBM ç¤ºä¾‹ï¼‰ ===
with tab6:
    st.subheader("ğŸ§­ ç‰¹å¾é‡è¦æ€§ï¼ˆLGBM ç¤ºä¾‹ï¼‰")
    if fi_df is None or fi_df.empty:
        st.info("æœªæ‰¾åˆ° metrics/feature_importance_lgb.csvã€‚ä»…å½“å¯¼å‡ºçš„æ¨¡å‹ä¸ºå¸¦é¢„å¤„ç†çš„ LGBM pipeline ä¸”ä¿å­˜äº†é‡è¦æ€§æ‰æ˜¾ç¤ºã€‚")
    else:
        import altair as alt
        topn = st.slider("å±•ç¤ºå‰ N", 10, min(50, len(fi_df)), min(25, len(fi_df)))
        plot_df = fi_df.sort_values("importance", ascending=False).head(topn)
        chart = alt.Chart(plot_df).mark_bar().encode(
            x=alt.X("importance:Q"),
            y=alt.Y("feature:N", sort="-x"),
            tooltip=["feature","importance"]
        ).properties(height=600)
        st.altair_chart(chart, use_container_width=True)

# ==== å¯é€‰ï¼šç¦»çº¿æ¨æ–­ï¼ˆä»…å½“ models/*.joblib å­˜åœ¨æ—¶å¯ç”¨ï¼‰ ====
if MODEL_DIR.exists() and any(MODEL_DIR.glob("*.joblib")):
    st.divider()
    st.subheader("ğŸ§ª ç¦»çº¿æ¨æ–­ï¼ˆæ¼”ç¤ºï¼‰")
    st.caption("ä¸Šä¼ å°‘é‡ CSVï¼ˆåˆ—éœ€ä¸è®­ç»ƒä¸€è‡´ï¼‰ã€‚æœ¬åŠŸèƒ½ä¾èµ–ä½ å¯¼å‡ºçš„ pipelineï¼ˆå«é¢„å¤„ç†ï¼‰ã€‚")
    up = st.file_uploader("ä¸Šä¼  CSVï¼ˆå°äº 5MBï¼‰", type=["csv"])
    if up is not None:
        import joblib
        pick_model = st.selectbox(
            "é€‰æ‹©å·²å¯¼å‡ºæ¨¡å‹", [p.name for p in MODEL_DIR.glob("*.joblib")]
        )
        mdl = joblib.load(MODEL_DIR / pick_model)
        df = pd.read_csv(up)
        try:
            yhat = mdl.predict(df)
            st.write("é¢„æµ‹å‰ 20 è¡Œï¼š", pd.DataFrame({"pred": yhat}).head(20))
            if hasattr(mdl, "predict_proba"):
                proba = mdl.predict_proba(df)
                st.write("æ¦‚ç‡ï¼ˆå‰ 5 è¡Œï¼‰ï¼š", pd.DataFrame(proba).head(5))
        except Exception as e:
            st.error(f"æ¨æ–­å¤±è´¥ï¼š{e}")
